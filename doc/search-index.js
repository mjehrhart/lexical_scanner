var searchIndex = JSON.parse('{\
"lexical_scanner":{"doc":"","t":[0,0,5,5,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,4,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,0,0,0,3,11,11,11,11,0,11,12,11,0,11,12,0,12,12,11,11,11,11,0,3,11,11,11,11,11,11,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,11,11,11,11,11,11,11,11,11,11,11],"n":["enums","lexer","lexer","lexer_as_str","And","AndAnd","AndEq","At","Backslash","BitCharacterCode7","BitCharacterCode8","BlockCommentStart","BlockCommentStop","BracketLeft","BracketRight","Byte","ByteString","Caret","CaretEq","CarriageReturn","Character","Colon","Comma","CurlyBraceLeft","CurlyBraceRight","Dollar","Dot","DotDot","DotDotDot","DotDotEq","DoubleQuote","Eq","EqEq","FatArrow","Floating","Ge","Gt","KW_As","KW_Async","KW_Await","KW_Break","KW_Const","KW_Contine","KW_Crate","KW_Dyn","KW_Else","KW_Enum","KW_Extern","KW_False","KW_Fn","KW_For","KW_If","KW_Impl","KW_In","KW_Let","KW_Loop","KW_Match","KW_Mod","KW_Move","KW_Mut","KW_Pub","KW_Ref","KW_Return","KW_SELF","KW_Self","KW_Static","KW_Struct","KW_Super","KW_Trait","KW_True","KW_Type","KW_Union","KW_Unsafe","KW_Use","KW_Where","KW_While","Le","LineComment","Lt","Minus","MinusEq","Newline","Not","NotEq","Null","Numeric","Or","OrEq","OrOr","ParenLeft","ParenRight","PathSep","Percent","PercentEq","Plus","PlusEq","Pound","Question","RArrow","RawByteString","RawString","Semi","Shl","ShlEq","Shr","ShrEq","SingleQuote","Slash","SlashEq","Star","StarEq","Stopped","String","Tab","Token","Undefined","Underscore","WhiteSpace","Word","borrow","borrow_mut","clone","clone_into","deref","eq","fmt","from","into","ne","to_owned","try_from","try_into","type_id","0","0","0","0","0","0","0","0","0","0","0","0","0","0","0","generics","lexer","generic","RawString","borrow","borrow_mut","clone","clone_into","escapes","fmt","found","from","generic","into","kind","numeric","removals","start","to_owned","try_from","try_into","type_id","lexer","Tokenizer","borrow","borrow_mut","bracket_delimiters","check_if_keyword","clone","clone_into","expr","fmt","from","into","into_iter","is_escaped","is_lesser_punctutation","is_math_operator","is_new_line","is_numeric_with_dot","is_numeric_with_dot_eq_underscore","is_punctuation","is_statement_delim","is_whitespace","is_word","keywords","load_keywords","new","next","next_punctuation","starts_with_double_quote","to_owned","transform_special_tokens_into_raw_byte_tokens","translate_token_to_keyword_token","try_from","try_into","type_id"],"q":["lexical_scanner","","","","lexical_scanner::enums","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","lexical_scanner::enums::Token","","","","","","","","","","","","","","","lexical_scanner::lexer","","lexical_scanner::lexer::generics","lexical_scanner::lexer::generics::generic","","","","","","","","","","","","","","","","","","","lexical_scanner::lexer::lexer","lexical_scanner::lexer::lexer::lexer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"d":["","","Constructs a vector of tokens. This straight forward …","Constructs a vector of tokens. This straight forward …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Token field and description for lexical scanner","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The lexer procceses the input converts to a vector of …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Transforms tokens into Token::RawString, …","","","",""],"i":[0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,17,17,17,17,0,17,17,17,0,17,17,0,17,17,17,17,17,17,0,0,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18],"f":[null,null,[[["str",15]],["vec",3,[["token",4]]]],[[["str",15]],["vec",3,[["token",4]]]],null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[],["token",4]],[[]],[[]],[[["token",4]],["bool",15]],[[["formatter",3]],["result",6]],[[]],[[]],[[["token",4]],["bool",15]],[[]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[],["rawstring",3]],[[]],null,[[["formatter",3]],["result",6]],null,[[]],null,[[]],null,null,null,null,[[]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,null,[[]],[[]],[[["char",15]],["bool",15]],[[["str",15]],["option",4,[["token",4]]]],[[],["tokenizer",3]],[[]],null,[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],[[["char",15]],["bool",15]],null,[[],["hashmap",3,[["str",15],["token",4]]]],[[["str",15]]],[[],["option",4,[["token",4]]]],[[["string",3],["peekable",3,[["chars",3]]]]],[[["char",15]],["bool",15]],[[]],[[["vec",3,[["token",4]]]],["vec",3,[["token",4]]]],[[["token",4],["string",3]],["option",4,[["token",4]]]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]]],"p":[[4,"Token"],[13,"BitCharacterCode7"],[13,"BitCharacterCode8"],[13,"BlockCommentStart"],[13,"BlockCommentStop"],[13,"Byte"],[13,"ByteString"],[13,"Character"],[13,"LineComment"],[13,"Floating"],[13,"Numeric"],[13,"RawString"],[13,"RawByteString"],[13,"Stopped"],[13,"String"],[13,"Word"],[3,"RawString"],[3,"Tokenizer"]]}\
}');
if (window.initSearch) {window.initSearch(searchIndex)};